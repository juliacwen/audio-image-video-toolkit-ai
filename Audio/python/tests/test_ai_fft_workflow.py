#!/usr/bin/env python3
"""
test_ai_fft_workflow.py

 * Author: Julia Wen wendigilane@gmail.com
 * Date: 2025-09-11

 - nn_module unit tests (MLP, NN, RNN) and end-to-end workflow test.
 - This version ensures WAV/CSV/spectrum files are generated by the test
   itself if calling the external generator fails.
"""

import importlib.util
from pathlib import Path
import numpy as np
import torch
import pytest
import subprocess
import wave

from ai_tools import nn_module, ai_fft_workflow

# ----------------------------
# Label map for files
# ----------------------------
LABEL_MAP = {"16bit": 0, "24bit": 1, "float32": 2}
WAV_PARAMS = {
    "16bit": "PCM_16",
    "24bit": "PCM_24",
    "float32": "FLOAT",
}

# ----------------------------
# Fallback generator (used only by tests if the external tool fails)
# ----------------------------
def _generate_fallback(wav_file: Path, csv_file: Path, spectrum_file: Path,
                       freq: float = 1000.0, sr: int = 8000, duration: float = 1.0):
    """Generate a simple tone WAV, a sample CSV, and a small spectrogram CSV."""
    n_samples = int(sr * duration)
    t = np.linspace(0, duration, n_samples, endpoint=False)
    amplitude = 0.5
    samples_f = amplitude * np.sin(2 * np.pi * freq * t)

    # write 16-bit PCM WAV
    int_samples = np.int16(samples_f * 32767)
    wav_file.parent.mkdir(parents=True, exist_ok=True)
    with wave.open(str(wav_file), "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 2 bytes = 16 bits
        wf.setframerate(sr)
        wf.writeframes(int_samples.tobytes())

    # write simple time/sample CSV
    with open(csv_file, "w") as f:
        f.write("time,sample\n")
        for ti, s in zip(t, samples_f):
            f.write(f"{ti:.6f},{s:.6f}\n")

    # build a small spectrogram-like matrix (n_frames x n_bins)
    n_frames = 8
    frame_len = max(32, n_samples // n_frames)
    nfft = 64
    spec_rows = []
    for i in range(n_frames):
        start = i * frame_len
        frame = samples_f[start:start + frame_len]
        if frame.size < frame_len:
            frame = np.pad(frame, (0, frame_len - frame.size))
        window = np.hanning(frame_len)
        fft = np.abs(np.fft.rfft(frame * window, n=nfft))
        spec_rows.append(fft)
    spec = np.array(spec_rows)  # shape: (n_frames, n_bins)

    # write spectrogram CSV with header then rows
    with open(spectrum_file, "w") as f:
        header = ",".join(f"b{i}" for i in range(spec.shape[1]))
        f.write(header + "\n")
        for row in spec:
            f.write(",".join(f"{v:.6f}" for v in row) + "\n")

    print(f"[test fallback] Generated: {wav_file} {csv_file} {spectrum_file}")

# ----------------------------
# Helper: ensure WAV/CSV/spectrum exist (tries external tool, falls back)
# ----------------------------
def ensure_test_data(out_dir: Path, suffix: str):
    """Ensure WAV, CSV and spectrum CSV exist for a given suffix.

    Tries to call ai_fft_workflow.run_wav_freq_csv; if that raises or the
    files are not present afterwards, generate fallback files locally.
    """
    subtype = WAV_PARAMS[suffix]
    wav_file = out_dir / f"tone_{suffix}.wav"
    csv_file = out_dir / f"tone_{suffix}.csv"
    spectrum_file = out_dir / f"tone_{suffix}_spectrum.csv"

    out_dir.mkdir(parents=True, exist_ok=True)

    # First, try the existing workflow's runner (preferred)
    try:
        ai_fft_workflow.run_wav_freq_csv(out_dir, suffix, subtype)
    except subprocess.CalledProcessError as e:
        print(f"[test] External generator returned non-zero exit code: {getattr(e,'returncode',None)}")
        if getattr(e, "stderr", None):
            print("[test] External stderr:\n", e.stderr)
        print("[test] Falling back to test-local generator.")
        _generate_fallback(wav_file, csv_file, spectrum_file, freq=1000, sr=8000, duration=1.0)
    except FileNotFoundError as e:
        # Binary not found or other file-not-found issues
        print("[test] External generator not found or failed:", e)
        print("[test] Falling back to test-local generator.")
        _generate_fallback(wav_file, csv_file, spectrum_file, freq=1000, sr=8000, duration=1.0)
    except Exception as e:
        # Catch-all: ensure tests still proceed but surface useful info
        print("[test] External generator raised exception:", type(e).__name__, e)
        print("[test] Falling back to test-local generator.")
        _generate_fallback(wav_file, csv_file, spectrum_file, freq=1000, sr=8000, duration=1.0)

    # If the external runner returned but did not create files, fall back as well
    missing = [f for f in (wav_file, csv_file, spectrum_file) if not f.exists()]
    if missing:
        print("[test] External generator did not create expected files:", missing)
        print("[test] Using test-local fallback generator now.")
        _generate_fallback(wav_file, csv_file, spectrum_file, freq=1000, sr=8000, duration=1.0)

    # Final asserts: tests should fail with a clear message if generation failed
    assert wav_file.exists(), f"WAV not generated: {wav_file}"
    assert csv_file.exists(), f"CSV not generated: {csv_file}"
    assert spectrum_file.exists(), f"Spectrum CSV not generated: {spectrum_file}"

    return wav_file, csv_file, spectrum_file

# ----------------------------
# Existing parameterized tests for nn_module
# ----------------------------
@pytest.mark.parametrize("model_type", ["MLP", "RNN"])
@pytest.mark.parametrize("suffix", ["16bit", "24bit", "float32"])
def test_model_training_per_file(suffix, model_type):
    out_dir = Path(__file__).parent / "ai_tools" / "test_output"
    out_dir.mkdir(exist_ok=True)
    _, _, spectrum_file = ensure_test_data(out_dir, suffix)

    # Patch label mapping for this test
    def patched_label_from_file(f):
        return LABEL_MAP[suffix]

    # ----------------------------
    # MLP
    # ----------------------------
    if model_type == "MLP":
        original_load = nn_module.load_spectra

        def patched_load_spectra(files):
            data = np.loadtxt(files[0], delimiter=",", skiprows=1).flatten()
            X = np.array([data])
            y = np.array([patched_label_from_file(files[0])])
            return X, y

        nn_module.load_spectra = patched_load_spectra
        model = nn_module.train_MLP([spectrum_file])
        assert model is not None
        print(f"MLP model trained successfully on {suffix} spectrum.")
        nn_module.load_spectra = original_load

    # ----------------------------
    # RNN
    # ----------------------------
    elif model_type == "RNN":
        original_load_rnn = nn_module.load_spectra_rnn

        def patched_load_spectra_rnn(files):
            data = np.loadtxt(files[0], delimiter=",", skiprows=1)
            X = data[np.newaxis, :, :]  # (1, seq_len, features)
            y = np.array([patched_label_from_file(files[0])])
            input_size = X.shape[2]
            return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long), input_size

        nn_module.load_spectra_rnn = patched_load_spectra_rnn
        model = nn_module.train_rnn(
            [spectrum_file], hidden_size=16, num_layers=1, num_classes=len(LABEL_MAP), epochs=5
        )
        assert isinstance(model, nn_module.SpectrumRNN)
        print(f"RNN model trained successfully on {suffix} spectrum.")

        X, y, _ = nn_module.load_spectra_rnn([spectrum_file])
        with torch.no_grad():
            outputs = model(X)
        assert outputs.shape[0] == 1
        assert outputs.shape[1] == len(LABEL_MAP)
        print(f"RNN forward pass successful, output shape verified for {suffix}.")

        nn_module.load_spectra_rnn = original_load_rnn

# ----------------------------
# New PyTorch NN tests
# ----------------------------
@pytest.mark.parametrize("suffix", ["16bit", "24bit", "float32"])
def test_model_training_per_file_nn(suffix):
    """
    Test new PyTorch feedforward NN (SpectrumNN) per spectrum file.
    """
    out_dir = Path(__file__).parent / "ai_tools" / "test_output"
    out_dir.mkdir(exist_ok=True)
    _, _, spectrum_file = ensure_test_data(out_dir, suffix)

    original_load = nn_module.load_spectra_nn

    def patched_load_spectra_nn(files):
        data = np.loadtxt(files[0], delimiter=",", skiprows=1).flatten()
        X = np.array([data])
        y = np.array([LABEL_MAP[suffix]])
        input_size = X.shape[1]
        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long), input_size

    nn_module.load_spectra_nn = patched_load_spectra_nn
    model = nn_module.train_nn([spectrum_file], hidden_size=16, epochs=5)
    assert isinstance(model, nn_module.SpectrumNN)
    print(f"PyTorch NN model trained successfully on {suffix} spectrum.")

    X, y, _ = nn_module.load_spectra_nn([spectrum_file])
    with torch.no_grad():
        outputs = model(X)
    assert outputs.shape[0] == 1
    assert outputs.shape[1] == len(LABEL_MAP)
    print(f"SpectrumNN forward pass successful, output shape verified for {suffix}.")

    nn_module.load_spectra_nn = original_load

# ----------------------------
# End-to-end workflow loader
# ----------------------------
def load_workflow_module():
    script = Path(__file__).parent / "ai_tools" / "ai_fft_workflow.py"
    spec = importlib.util.spec_from_file_location("ai_fft_workflow", script)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

# ----------------------------
# Parameterized end-to-end workflow test
# ----------------------------
@pytest.mark.parametrize("suffix", ["16bit", "24bit", "float32"])
@pytest.mark.parametrize("model_type", ["MLP", "RNN", "NN"])
def test_ai_fft_predictions_param(suffix, model_type):
    """End-to-end workflow: generate WAVs, spectra, train nn_module model, validate predictions."""
    module = load_workflow_module()
    preds = module.main()  # dict {(filename, model): probs}

    out_dir = Path(__file__).parent / "ai_tools" / "test_output"
    pred_file = out_dir / "predictions.txt"
    assert pred_file.exists(), "predictions.txt was not created"

    fname = f"tone_{suffix}_spectrum.csv"
    key = (fname, model_type)
    assert key in preds, f"Prediction missing for {fname} {model_type}"

    arr = np.array(preds[key])
    # Must match number of classes
    assert arr.shape[0] == len(LABEL_MAP)
    # Probabilities in [0,1]
    assert np.all((arr >= 0) & (arr <= 1))
    # Sum of probabilities ~1
    assert np.isclose(arr.sum(), 1.0, atol=1e-3)

    # Check WAV, CSV, spectrum existence
    wav_file = out_dir / f"tone_{suffix}.wav"
    csv_file = out_dir / f"tone_{suffix}.csv"
    spec_file = out_dir / f"tone_{suffix}_spectrum.csv"
    assert wav_file.exists()
    assert csv_file.exists()
    assert spec_file.exists()

